[
    {
        "id": "2024_04_28.md",
        "name": "2024_04_28",
        "content": [
            "Things to do today\nDONE Finish watching Kaggle Competitions YouTube video\n:logbook:\n      CLOCK: [2024-04-28 Sun 17:48:06]--[2024-04-28 Sun 17:48:07] =>  00:00:01\n      CLOCK: [2024-04-28 Sun 17:48:07]--[2024-04-28 Sun 17:48:17] =>  00:00:10\n:END:\nDONE Finish watching GenAI for everybody(DeepLearning.AI)\n:logbook:\n      CLOCK: [2024-04-28 Sun 11:44:25]--[2024-04-28 Sun 11:44:27] =>  00:00:02\n:END:\nDONE Finish Data Science Project(predicting house price)\nTODO Finish Git+Github video\nDONE Finish Logseq video #[[beginner guide]]\nhttps://www.youtube.com/watch?v=asEesjv0kTs\n\n\n\n",
            "DONE Finish watching Kaggle Competitions YouTube video\n:logbook:\n      CLOCK: [2024-04-28 Sun 17:48:06]--[2024-04-28 Sun 17:48:07] =>  00:00:01\n      CLOCK: [2024-04-28 Sun 17:48:07]--[2024-04-28 Sun 17:48:17] =>  00:00:10\n:END:",
            "DONE Finish watching GenAI for everybody(DeepLearning.AI)\n:logbook:\n      CLOCK: [2024-04-28 Sun 11:44:25]--[2024-04-28 Sun 11:44:27] =>  00:00:02\n:END:",
            "DONE Finish Data Science Project(predicting house price)",
            "TODO Finish Git+Github video",
            "DONE Finish Logseq video #[[beginner guide]]\nhttps://www.youtube.com/watch?v=asEesjv0kTs\n\n",
            "https://www.youtube.com/watch?v=asEesjv0kTs",
            "Been thinking about [[collaboration]]\nHow can logseq help teams? #professional\nHow can Logseq help researchers? #[[[research workflows]]]\n\n",
            "How can logseq help teams? #professional",
            "How can Logseq help researchers? #[[[research workflows]]]",
            "Started reading an article about business process improvement\nIt was interesting how they focused on not automating upfront\n\n",
            "It was interesting how they focused on not automating upfront",
            "Started watching API, FASTAPI videos",
            "Started [[Chatbot]] project, need to change the endpoint to local rather than OpenAI\n[https://github.com/ILikeAI/AlwaysReddy]\nThis is the way https://github.com/ILikeAI/AlwaysReddy/issues/9\n\n",
            "[https://github.com/ILikeAI/AlwaysReddy]",
            "This is the way https://github.com/ILikeAI/AlwaysReddy/issues/9",
            "\nNext check out\n\nThings to try in the future\nnext check out [[oogabooga]]\nhttps://github.com/oobabooga/text-generation-webui\n\n\n[[ollama 8b]]\nHow to use [[AlwayReddy]] with [[Ollama]] https://www.youtube.com/watch?v=BMYwT58rtxw\n\n\nhttps://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b\n[[Data Scientist Roadmap 2024]] https://github.com/xandie985/data-scientist-roadmap2024\n\n\n\n",
            "Things to try in the future\nnext check out [[oogabooga]]\nhttps://github.com/oobabooga/text-generation-webui\n\n\n[[ollama 8b]]\nHow to use [[AlwayReddy]] with [[Ollama]] https://www.youtube.com/watch?v=BMYwT58rtxw\n\n\nhttps://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b\n[[Data Scientist Roadmap 2024]] https://github.com/xandie985/data-scientist-roadmap2024\n\n",
            "next check out [[oogabooga]]\nhttps://github.com/oobabooga/text-generation-webui\n\n",
            "https://github.com/oobabooga/text-generation-webui",
            "[[ollama 8b]]\nHow to use [[AlwayReddy]] with [[Ollama]] https://www.youtube.com/watch?v=BMYwT58rtxw\n\n",
            "How to use [[AlwayReddy]] with [[Ollama]] https://www.youtube.com/watch?v=BMYwT58rtxw",
            "https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b",
            "[[Data Scientist Roadmap 2024]] https://github.com/xandie985/data-scientist-roadmap2024",
            "[[Datasette]]\nhttps://github.com/datasette/datasette-extract\n\n",
            "https://github.com/datasette/datasette-extract",
            "Clothes swap salvton [[comfyui]]\nhttps://github.com/cozymantis/clothes-swap-salvton-comfyui-workflow/tree/main\nhttps://github.com/fashn-AI/tryondiffusion\n\n",
            "https://github.com/cozymantis/clothes-swap-salvton-comfyui-workflow/tree/main",
            "https://github.com/fashn-AI/tryondiffusion",
            "GPTs are GPTs: An Early Look at the [[Labor Market]] Impact Potential of [[Large Language Models]]\nhttps://arxiv.org/pdf/2303.10130\n\n",
            "https://arxiv.org/pdf/2303.10130",
            "The Potentially Large Effects of [[Artificial Intelligence]] on [[Economic Growth]] (Briggs/Kodnani) #[[Global Economics Analyst]]\nhttps://www.gspublishing.com/content/research/en/reports/2023/03/27/d64e052b-0f6e-45d7-967b-d7be35fabd16.html\n\n",
            "https://www.gspublishing.com/content/research/en/reports/2023/03/27/d64e052b-0f6e-45d7-967b-d7be35fabd16.html"
        ]
    },
    {
        "id": "2024_04_29.md",
        "name": "2024_04_29",
        "content": [
            "[[wolframs]] [[Large Language Models]]\nhttps://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw\n\n",
            "https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw",
            "[[Mentor]]\nconfirm a date for the 1st mentor session with [[Teese]] #Reed\n\n",
            "confirm a date for the 1st mentor session with [[Teese]] #Reed",
            "DONE Finish watching #[[ChatGPT Prompt Engineering for Developers]]\nhttps://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/2/guidelines\n\n",
            "https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/2/guidelines",
            "\nWeb UI chatbots to try\n",
            "Experiment with prompting a  [[large language model]] ([[LLM]]), you can visit one of the chatbots linked below:\n[ChatGPT] from [[OpenAI]]\nGemini (formerly Bard) from Google\nBing Chat from Microsoft\n\n",
            "[ChatGPT] from [[OpenAI]]",
            "Gemini (formerly Bard) from Google",
            "Bing Chat from Microsoft"
        ]
    },
    {
        "id": "2024_04_30.md",
        "name": "2024_04_30",
        "content": [
            "[[Job]]s break down into [[tasks]] #[[Occupation keyword]]#[[Gen AI]]\nhttps://www.onetonline.org/\n\n",
            "https://www.onetonline.org/",
            "Notetaking [[ChatGPT Prompt Engineering for Developers]]\n    -\n\nPrompting Principles ¶\n\nPrinciple 1: Write clear and specific instructions\n\nTactics \n\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything like: ``, \"\"\", < >, ,:`\n\n\n\nTactic 2: Ask for a structured output \n\nJSON, HTML\n\n\n\nTactic 3: Ask the model to check whether conditions are satisfied\n\n\nTactic 4: \"Few-shot\" prompting\n\n\n\n\n\n\n",
            "\nPrompting Principles ¶\n",
            "Principle 1: Write clear and specific instructions\n\nTactics \n\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything like: ``, \"\"\", < >, ,:`\n\n\n\nTactic 2: Ask for a structured output \n\nJSON, HTML\n\n\n\nTactic 3: Ask the model to check whether conditions are satisfied\n\n\nTactic 4: \"Few-shot\" prompting\n\n\n\n\n",
            "\nTactics \n\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything like: ``, \"\"\", < >, ,:`\n\n\n\nTactic 2: Ask for a structured output \n\nJSON, HTML\n\n\n\nTactic 3: Ask the model to check whether conditions are satisfied\n\n\nTactic 4: \"Few-shot\" prompting\n\n\n",
            "\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything like: ``, \"\"\", < >, ,:`\n\n",
            "Delimiters can be anything like: ``, \"\"\", < >, ,:`",
            "\nTactic 2: Ask for a structured output \n\nJSON, HTML\n\n",
            "JSON, HTML",
            "\nTactic 3: Ask the model to check whether conditions are satisfied\n",
            "\nTactic 4: \"Few-shot\" prompting\n",
            "Principle 2: Give the model time to “think”\n\nTactic 1: Specify the steps required to complete a task, Ask for output in a specified format\n\n\nTactic 2: Instruct the model to work out its own solution before rushing to a conclusion\n\n\n",
            "\nTactic 1: Specify the steps required to complete a task, Ask for output in a specified format\n",
            "\nTactic 2: Instruct the model to work out its own solution before rushing to a conclusion\n",
            "\n[[Model Limitations]]: [[Hallucinations]]\n",
            "Reducing hallucinations:\nFirst find relevant information,then answer the question based on the relevant information.\n\n",
            "First find relevant information,then answer the question based on the relevant information.",
            "How Diffusion Models Work\n**\n\n",
            "**"
        ]
    },
    {
        "id": "2024_05_04.md",
        "name": "2024_05_04",
        "content": [
            "\n#TODO list\n",
            "TODO Take AWS course and exam\nhttps://community.cloudwolf.com/c/data-science-and-machine-learning-in-the-cloud\n\n",
            "https://community.cloudwolf.com/c/data-science-and-machine-learning-in-the-cloud",
            "Apply for IBM Business Analyst program(Linkedin)\nhttps://www.linkedin.com/jobs/view/3898702682/?refId=3fca3d4a-2f19-4cb2-958a-b15baad3bd70&trackingId=%2Fm%2FBwu99SEeSEzHnHUYQoA%3D%3D&trk=flagship3_job_home_savedjobs\n\n",
            "https://www.linkedin.com/jobs/view/3898702682/?refId=3fca3d4a-2f19-4cb2-958a-b15baad3bd70&trackingId=%2Fm%2FBwu99SEeSEzHnHUYQoA%3D%3D&trk=flagship3_job_home_savedjobs",
            "Go through all these job roles.\nhttps://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED\n\n",
            "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED",
            "Most important thing:- Power BI projects and share in Linkedin\n-\n",
            "-",
            "Project ideas:\n\nHR Analytics Data Set(EDA,Prediction?)\n- https://www.kaggle.com/datasets/raminhuseyn/hr-analytics-data-set/code?datasetId=4812222&sortBy=voteCount\n\n\n",
            "\nHR Analytics Data Set(EDA,Prediction?)\n- https://www.kaggle.com/datasets/raminhuseyn/hr-analytics-data-set/code?datasetId=4812222&sortBy=voteCount\n"
        ]
    },
    {
        "id": "2024_05_12.md",
        "name": "2024_05_12",
        "content": [
            "\n[[Power BI channel project]] ([[Nicola Sagay]], [[Sowjanya Surapneni]], [[Jing Li]])\n\nYoutube channel\nDashboards in the website(Nicola already bought a website)\nDONE Jing share the dataset in google drive\nfrequecy of the meeting: 2 weeks\nhow often to meet: next Sunday 19/5/24  14:00\nWe also need to figure out what projects we want to present and do and pitch\n\n",
            "Youtube channel",
            "Dashboards in the website(Nicola already bought a website)",
            "DONE Jing share the dataset in google drive",
            "frequecy of the meeting: 2 weeks",
            "how often to meet: next Sunday 19/5/24  14:00",
            "We also need to figure out what projects we want to present and do and pitch",
            "Interview Intern preparation",
            "Machine learning projects"
        ]
    },
    {
        "id": "2024_05_16.md",
        "name": "2024_05_16",
        "content": [
            "reaction diffusion turing",
            "Ontology",
            "LLM",
            "CSM 3D Viewer(not in fashion yet)"
        ]
    },
    {
        "id": "2024_05_17.md",
        "name": "2024_05_17",
        "content": [
            "Skills and Work presentation for [[Lab Technician]] part time role at [[MediaCityUK]] #[[MediaCity]]",
            "[[Interview preparation]] Questions\nIntroduction and Background\nCan you please introduce yourself and provide a brief overview of your educational background and any relevant experience you have in computer science, AI, or machine learning?\n\nMy name is Jing Li, and you can call me Jing. I have a degree in economics and worked in China for almost 10 years before moving to the UK 8 years ago. In Manchester, I worked as a Merchandiser Manager at a start-up clothing wholesale company for more than 5 years. My roles in the fashion industry, both as a sales representative and as a merchandiser, involved acting as a bridge between clients and suppliers. Three years ago, I left the company to take on more responsibility by starting a sustainable wholesale clothing business. Unfortunately, due to increased running costs caused by global events – covid and the war in Ukraine, I had to close the business after a year. Currently, I am a full-time caregiver for my 2-year-old son and have been studying data science in my spare time for almost two years.  I have completed three free bootcamps and several online courses. I have also collaborated with co-workers on a few projects and undertaken some independent projects, gaining practical experience in the field.\n\n\n\nCareer Transition\nWhat motivated you to make this significant career change?\n  \"After I closed my business, I started looking into new career paths to support my family. That's when I discovered data science, and it immediately grabbed my attention. The idea of making informed decisions and predicting trends really resonated with me. In my previous jobs, I did some basic analyse on  order dataset to identify best-selling products and compared sales data year-over-year to understand performance. The trends that I predicted had a massive impact to the business, but they also left me with some unanswered questions about why they happened, so moving into data science like a natural step, as it allowed me to formalize my skills and gain a deeper understanding of my past successes.\"  \nHow do you feel your experience in the fashion industry has prepared you for a role in data science and AI?\n  \"My experience in the fashion industry has honed my skills in trend analysis, project management, and customer-centric problem-solving. These skills are highly transferable to data science, where understanding patterns, managing data projects, and addressing client needs are crucial. Additionally, my creative background helps me approach data-driven problems with an innovative mindset.\"  \n\n\nTechnical Skills\nCan you elaborate on a specific challenge you faced while learning Python and how you overcame it?\n  \"Python is the first thing that I learnt for data science so understanding the syntax and logic of Python was a little challenge for me as I transitioned from a non-technical background. To overcome this, I dedicated time to practice coding daily, engaged in online forums for support, and completed numerous hands-on projects. This consistent practice helped me build confidence and proficiency in Python.\"  \nWhich machine learning project did you find the most challenging and why?\n  \"The project where I predicted house prices in Bangalore was the most challenging. It involved handling a large dataset with numerous features, requiring extensive data cleaning and preprocessing. One of the major challenges was dealing with missing values and outliers that could skew the results. Additionally, selecting the right machine learning model and tuning its hyperparameters to improve accuracy required a deep understanding of various algorithms and techniques. Implementing feature engineering to enhance model performance was another complex task. Despite these challenges, the project was incredibly rewarding as it provided me with a comprehensive understanding of end-to-end machine learning workflows and honed my problem-solving skills.\"  \nHow do you stay updated with the latest developments in AI and machine learning?\n  \"I regularly attend webinars and meetup groups, and participate in online courses. Platforms like Udemy and Deep Learning AI offer excellent resources for continuing education and use Kaggle dataset to practice my skills and active in online communities and forums where professionals discuss the latest trends and advancements in AI and machine learning.\"  \n\n\nProject Management\nDescribe a time when you had to manage multiple projects simultaneously. How did you prioritize and ensure timely completion?\n  \"In my role as a Merchandiser Manager, I often managed multiple client accounts and product lines. I prioritized tasks based on client deadlines, the potential impact on business, and resource availability. Effective communication, a well-organized schedule, and delegation of tasks to my team were key strategies that ensured timely completion of projects.\"  \nCan you give an example of a project where you led a team? What were some key takeaways from that experience?\n  \"I managed a team responsible for sourcing fabrics, new designs and coordinating with factories to produce new clothing lines. This involved setting clear objectives, delegating tasks according to each team member’s strengths, and maintaining a timeline to ensure deadlines were met. One of the challenges was managing the feedback loop between the design team and the factory to ensure the samples met our quality standards. The key takeaways from this experience were the importance of effective communication, the ability to adapt to changing circumstances, and the value of building a cohesive team where each member’s contributions are recognized and leveraged. This experience underscored the importance of leadership in driving a project to successful completion through collaboration and strategic planning.\"\"  \n\n\nData Science Projects\nRegarding your EV charger location project, what specific techniques or algorithms did you use to identify optimal locations?\n  \"We were given this task in one of the bootcamp I did to make a proposal to the CEO to make informed decision whether to invest £2 million into an EV charger hub and help to find the best locations, we are a team of 10 members and divided our tasks into three groups and checked the desirability, feasibility, and viability to assess why this investment is beneficial. Our analysis included estimating customer numbers per day, identifying the best locations, determining the optimal number of EV chargers needed, and calculating the payback period for the initial investment. Based on these insights, we recommended purchasing enough chargers to meet demand up to a limit of 66 and using profits to buy additional chargers once breakeven is achieved. This approach ensures optimal resource allocation and maximizes profitability. Throughout this project, we demonstrated advanced Excel skills, particularly in building and adjusting a dynamic growth model. This comprehensive analysis provided a solid foundation for making informed investment decisions in the EV sector.  \nHow did you handle data quality and preprocessing in your machine learning projects?\n  \"Ensuring data quality was a critical first step in all my projects. I used techniques like data cleaning, normalization, and handling missing values to preprocess the data. For example, in the house price prediction project, I removed outliers, imputed missing values, and standardized numerical features to improve model performance.\"  \nCan you walk us through the process of your house price prediction project? What were the key steps you took from data collection to model deployment?\n  \"The house price prediction project involved several key steps. First, I sourced the dataset from Kaggle. I then cleaned the data by dropping unnecessary features, handling missing values, and encoding categorical variables. I created a new feature, 'price per square foot,' to capture the relationship between property size and price, enhancing the model's predictive accuracy. For model training, I used Linear Regression, achieving an initial accuracy of 84%. I then employed K-Fold cross-validation to measure model accuracy comprehensively. To find the best model, I compared Linear Regression, Lasso, and Decision Tree algorithms using GridSearchCV, and found that Linear Regression performed the best. Finally, I deployed the model to input data and receive price predictions.\"  \n\n\nCollaboration and Communication\nHow do you approach explaining complex technical concepts to non-technical stakeholders?\n  \"I focus on using clear, simple language. charts and graphs can also make complex data more understandable. For example, when explaining machine learning models, I often use visualizations to show how data points are classified or predicted, making it easier for non-technical stakeholders to grasp the concepts.\"  \nDescribe a situation where you had to collaborate with a multidisciplinary team. What were the challenges and how did you address them?\n  \"In the EV charger location project, we had team members from diverse backgrounds, including project manager, engineers, and business analysts. One challenge was ensuring everyone was on the same page with technical jargon and project goals. I facilitated regular meetings to align our objectives and encouraged open communication to address any misunderstandings promptly.\"  \n\n\nCreative and Innovative Thinking\nIn your fashion career, you mentioned creating a best-selling product. Can you share more about the creative process behind this success?\n  \"The creative process involved closely monitoring fashion trends, analyzing market demands, and collaborating with designers and suppliers. I used platforms like Pinterest and runway shows to gather inspiration and combined this with customer feedback to create a product that resonated with our target audience. Iterative testing and refinement were key to ensuring the product’s success.\"  \nHow do you approach innovation in your data science projects? Can you provide an example where you applied a creative solution to a technical problem?\n  \"I approach innovation by keeping an open mind and continuously exploring new methodologies and tools. In the EV charger location project, we creatively combined traditional clustering techniques with GIS data analysis to enhance our location predictions, which was a novel approach that significantly improved the accuracy of our results.\"  \n\n\nAlignment with MediaCity UK’s Goals\nHow do you envision your role as a Lab Technician contributing to the innovation projects at MediaCity?\n  \"I see myself contributing by bringing a unique perspective that blends creativity with technical expertise. My background in fashion and data science allows me to approach problems from different angles, fostering innovation. I am eager to support the team in integrating AI technologies into creative workflows, enhancing efficiency, and driving new possibilities in content creation.\"  \nWhat excites you the most about the opportunity to work at the Creative Industries Innovation Lab?\n  \"The most exciting aspect is the opportunity to work at the intersection of technology and creativity. MediaCity is known for its innovative projects, and being part of a team that pushes the boundaries of what AI can do in the creative industries is incredibly inspiring.\"  \nHow do you see AI transforming the creative industries, and what role do you want to play in this transformation?\n  \"AI has the potential to revolutionize content creation by automating tedious tasks, enhancing creative workflows, and enabling new forms of artistic expression. I want to play a role in developing and implementing AI-driven tools that empower artists and creators to explore new frontiers and streamline their processes.\"  \n\n\nFuture Aspirations\nWhere do you see yourself in five years, and how does this role at MediaCity fit into your career plans?\n  \"In five years, I see myself as a leading AI developer, working on groundbreaking projects that blend technology with creativity. This role at MediaCity is a perfect stepping stone, allowing me to apply my skills in a dynamic environment and contribute to innovative projects that will shape the future of the creative industries.\"  \nWhat are some areas of AI or machine learning that you are particularly interested in exploring further?\n  \"I am particularly interested in exploring generative models, such as Generative Adversarial Networks (GANs), and their applications in creating unique artistic content. Additionally, I am fascinated by the potential of AI in enhancing real-time workflows and interactive media, which are critical areas for the future of the creative industries.  \n\n\n\n",
            "Introduction and Background\nCan you please introduce yourself and provide a brief overview of your educational background and any relevant experience you have in computer science, AI, or machine learning?\n\nMy name is Jing Li, and you can call me Jing. I have a degree in economics and worked in China for almost 10 years before moving to the UK 8 years ago. In Manchester, I worked as a Merchandiser Manager at a start-up clothing wholesale company for more than 5 years. My roles in the fashion industry, both as a sales representative and as a merchandiser, involved acting as a bridge between clients and suppliers. Three years ago, I left the company to take on more responsibility by starting a sustainable wholesale clothing business. Unfortunately, due to increased running costs caused by global events – covid and the war in Ukraine, I had to close the business after a year. Currently, I am a full-time caregiver for my 2-year-old son and have been studying data science in my spare time for almost two years.  I have completed three free bootcamps and several online courses. I have also collaborated with co-workers on a few projects and undertaken some independent projects, gaining practical experience in the field.\n\n\n",
            "Can you please introduce yourself and provide a brief overview of your educational background and any relevant experience you have in computer science, AI, or machine learning?",
            "\nMy name is Jing Li, and you can call me Jing. I have a degree in economics and worked in China for almost 10 years before moving to the UK 8 years ago. In Manchester, I worked as a Merchandiser Manager at a start-up clothing wholesale company for more than 5 years. My roles in the fashion industry, both as a sales representative and as a merchandiser, involved acting as a bridge between clients and suppliers. Three years ago, I left the company to take on more responsibility by starting a sustainable wholesale clothing business. Unfortunately, due to increased running costs caused by global events – covid and the war in Ukraine, I had to close the business after a year. Currently, I am a full-time caregiver for my 2-year-old son and have been studying data science in my spare time for almost two years.  I have completed three free bootcamps and several online courses. I have also collaborated with co-workers on a few projects and undertaken some independent projects, gaining practical experience in the field.\n",
            "Career Transition\nWhat motivated you to make this significant career change?\n  \"After I closed my business, I started looking into new career paths to support my family. That's when I discovered data science, and it immediately grabbed my attention. The idea of making informed decisions and predicting trends really resonated with me. In my previous jobs, I did some basic analyse on  order dataset to identify best-selling products and compared sales data year-over-year to understand performance. The trends that I predicted had a massive impact to the business, but they also left me with some unanswered questions about why they happened, so moving into data science like a natural step, as it allowed me to formalize my skills and gain a deeper understanding of my past successes.\"  \nHow do you feel your experience in the fashion industry has prepared you for a role in data science and AI?\n  \"My experience in the fashion industry has honed my skills in trend analysis, project management, and customer-centric problem-solving. These skills are highly transferable to data science, where understanding patterns, managing data projects, and addressing client needs are crucial. Additionally, my creative background helps me approach data-driven problems with an innovative mindset.\"  \n\n",
            "What motivated you to make this significant career change?\n  \"After I closed my business, I started looking into new career paths to support my family. That's when I discovered data science, and it immediately grabbed my attention. The idea of making informed decisions and predicting trends really resonated with me. In my previous jobs, I did some basic analyse on  order dataset to identify best-selling products and compared sales data year-over-year to understand performance. The trends that I predicted had a massive impact to the business, but they also left me with some unanswered questions about why they happened, so moving into data science like a natural step, as it allowed me to formalize my skills and gain a deeper understanding of my past successes.\"  ",
            "How do you feel your experience in the fashion industry has prepared you for a role in data science and AI?\n  \"My experience in the fashion industry has honed my skills in trend analysis, project management, and customer-centric problem-solving. These skills are highly transferable to data science, where understanding patterns, managing data projects, and addressing client needs are crucial. Additionally, my creative background helps me approach data-driven problems with an innovative mindset.\"  ",
            "Technical Skills\nCan you elaborate on a specific challenge you faced while learning Python and how you overcame it?\n  \"Python is the first thing that I learnt for data science so understanding the syntax and logic of Python was a little challenge for me as I transitioned from a non-technical background. To overcome this, I dedicated time to practice coding daily, engaged in online forums for support, and completed numerous hands-on projects. This consistent practice helped me build confidence and proficiency in Python.\"  \nWhich machine learning project did you find the most challenging and why?\n  \"The project where I predicted house prices in Bangalore was the most challenging. It involved handling a large dataset with numerous features, requiring extensive data cleaning and preprocessing. One of the major challenges was dealing with missing values and outliers that could skew the results. Additionally, selecting the right machine learning model and tuning its hyperparameters to improve accuracy required a deep understanding of various algorithms and techniques. Implementing feature engineering to enhance model performance was another complex task. Despite these challenges, the project was incredibly rewarding as it provided me with a comprehensive understanding of end-to-end machine learning workflows and honed my problem-solving skills.\"  \nHow do you stay updated with the latest developments in AI and machine learning?\n  \"I regularly attend webinars and meetup groups, and participate in online courses. Platforms like Udemy and Deep Learning AI offer excellent resources for continuing education and use Kaggle dataset to practice my skills and active in online communities and forums where professionals discuss the latest trends and advancements in AI and machine learning.\"  \n\n",
            "Can you elaborate on a specific challenge you faced while learning Python and how you overcame it?\n  \"Python is the first thing that I learnt for data science so understanding the syntax and logic of Python was a little challenge for me as I transitioned from a non-technical background. To overcome this, I dedicated time to practice coding daily, engaged in online forums for support, and completed numerous hands-on projects. This consistent practice helped me build confidence and proficiency in Python.\"  ",
            "Which machine learning project did you find the most challenging and why?\n  \"The project where I predicted house prices in Bangalore was the most challenging. It involved handling a large dataset with numerous features, requiring extensive data cleaning and preprocessing. One of the major challenges was dealing with missing values and outliers that could skew the results. Additionally, selecting the right machine learning model and tuning its hyperparameters to improve accuracy required a deep understanding of various algorithms and techniques. Implementing feature engineering to enhance model performance was another complex task. Despite these challenges, the project was incredibly rewarding as it provided me with a comprehensive understanding of end-to-end machine learning workflows and honed my problem-solving skills.\"  ",
            "How do you stay updated with the latest developments in AI and machine learning?\n  \"I regularly attend webinars and meetup groups, and participate in online courses. Platforms like Udemy and Deep Learning AI offer excellent resources for continuing education and use Kaggle dataset to practice my skills and active in online communities and forums where professionals discuss the latest trends and advancements in AI and machine learning.\"  ",
            "Project Management\nDescribe a time when you had to manage multiple projects simultaneously. How did you prioritize and ensure timely completion?\n  \"In my role as a Merchandiser Manager, I often managed multiple client accounts and product lines. I prioritized tasks based on client deadlines, the potential impact on business, and resource availability. Effective communication, a well-organized schedule, and delegation of tasks to my team were key strategies that ensured timely completion of projects.\"  \nCan you give an example of a project where you led a team? What were some key takeaways from that experience?\n  \"I managed a team responsible for sourcing fabrics, new designs and coordinating with factories to produce new clothing lines. This involved setting clear objectives, delegating tasks according to each team member’s strengths, and maintaining a timeline to ensure deadlines were met. One of the challenges was managing the feedback loop between the design team and the factory to ensure the samples met our quality standards. The key takeaways from this experience were the importance of effective communication, the ability to adapt to changing circumstances, and the value of building a cohesive team where each member’s contributions are recognized and leveraged. This experience underscored the importance of leadership in driving a project to successful completion through collaboration and strategic planning.\"\"  \n\n",
            "Describe a time when you had to manage multiple projects simultaneously. How did you prioritize and ensure timely completion?\n  \"In my role as a Merchandiser Manager, I often managed multiple client accounts and product lines. I prioritized tasks based on client deadlines, the potential impact on business, and resource availability. Effective communication, a well-organized schedule, and delegation of tasks to my team were key strategies that ensured timely completion of projects.\"  ",
            "Can you give an example of a project where you led a team? What were some key takeaways from that experience?\n  \"I managed a team responsible for sourcing fabrics, new designs and coordinating with factories to produce new clothing lines. This involved setting clear objectives, delegating tasks according to each team member’s strengths, and maintaining a timeline to ensure deadlines were met. One of the challenges was managing the feedback loop between the design team and the factory to ensure the samples met our quality standards. The key takeaways from this experience were the importance of effective communication, the ability to adapt to changing circumstances, and the value of building a cohesive team where each member’s contributions are recognized and leveraged. This experience underscored the importance of leadership in driving a project to successful completion through collaboration and strategic planning.\"\"  ",
            "Data Science Projects\nRegarding your EV charger location project, what specific techniques or algorithms did you use to identify optimal locations?\n  \"We were given this task in one of the bootcamp I did to make a proposal to the CEO to make informed decision whether to invest £2 million into an EV charger hub and help to find the best locations, we are a team of 10 members and divided our tasks into three groups and checked the desirability, feasibility, and viability to assess why this investment is beneficial. Our analysis included estimating customer numbers per day, identifying the best locations, determining the optimal number of EV chargers needed, and calculating the payback period for the initial investment. Based on these insights, we recommended purchasing enough chargers to meet demand up to a limit of 66 and using profits to buy additional chargers once breakeven is achieved. This approach ensures optimal resource allocation and maximizes profitability. Throughout this project, we demonstrated advanced Excel skills, particularly in building and adjusting a dynamic growth model. This comprehensive analysis provided a solid foundation for making informed investment decisions in the EV sector.  \nHow did you handle data quality and preprocessing in your machine learning projects?\n  \"Ensuring data quality was a critical first step in all my projects. I used techniques like data cleaning, normalization, and handling missing values to preprocess the data. For example, in the house price prediction project, I removed outliers, imputed missing values, and standardized numerical features to improve model performance.\"  \nCan you walk us through the process of your house price prediction project? What were the key steps you took from data collection to model deployment?\n  \"The house price prediction project involved several key steps. First, I sourced the dataset from Kaggle. I then cleaned the data by dropping unnecessary features, handling missing values, and encoding categorical variables. I created a new feature, 'price per square foot,' to capture the relationship between property size and price, enhancing the model's predictive accuracy. For model training, I used Linear Regression, achieving an initial accuracy of 84%. I then employed K-Fold cross-validation to measure model accuracy comprehensively. To find the best model, I compared Linear Regression, Lasso, and Decision Tree algorithms using GridSearchCV, and found that Linear Regression performed the best. Finally, I deployed the model to input data and receive price predictions.\"  \n\n",
            "Regarding your EV charger location project, what specific techniques or algorithms did you use to identify optimal locations?\n  \"We were given this task in one of the bootcamp I did to make a proposal to the CEO to make informed decision whether to invest £2 million into an EV charger hub and help to find the best locations, we are a team of 10 members and divided our tasks into three groups and checked the desirability, feasibility, and viability to assess why this investment is beneficial. Our analysis included estimating customer numbers per day, identifying the best locations, determining the optimal number of EV chargers needed, and calculating the payback period for the initial investment. Based on these insights, we recommended purchasing enough chargers to meet demand up to a limit of 66 and using profits to buy additional chargers once breakeven is achieved. This approach ensures optimal resource allocation and maximizes profitability. Throughout this project, we demonstrated advanced Excel skills, particularly in building and adjusting a dynamic growth model. This comprehensive analysis provided a solid foundation for making informed investment decisions in the EV sector.  ",
            "How did you handle data quality and preprocessing in your machine learning projects?\n  \"Ensuring data quality was a critical first step in all my projects. I used techniques like data cleaning, normalization, and handling missing values to preprocess the data. For example, in the house price prediction project, I removed outliers, imputed missing values, and standardized numerical features to improve model performance.\"  ",
            "Can you walk us through the process of your house price prediction project? What were the key steps you took from data collection to model deployment?\n  \"The house price prediction project involved several key steps. First, I sourced the dataset from Kaggle. I then cleaned the data by dropping unnecessary features, handling missing values, and encoding categorical variables. I created a new feature, 'price per square foot,' to capture the relationship between property size and price, enhancing the model's predictive accuracy. For model training, I used Linear Regression, achieving an initial accuracy of 84%. I then employed K-Fold cross-validation to measure model accuracy comprehensively. To find the best model, I compared Linear Regression, Lasso, and Decision Tree algorithms using GridSearchCV, and found that Linear Regression performed the best. Finally, I deployed the model to input data and receive price predictions.\"  ",
            "Collaboration and Communication\nHow do you approach explaining complex technical concepts to non-technical stakeholders?\n  \"I focus on using clear, simple language. charts and graphs can also make complex data more understandable. For example, when explaining machine learning models, I often use visualizations to show how data points are classified or predicted, making it easier for non-technical stakeholders to grasp the concepts.\"  \nDescribe a situation where you had to collaborate with a multidisciplinary team. What were the challenges and how did you address them?\n  \"In the EV charger location project, we had team members from diverse backgrounds, including project manager, engineers, and business analysts. One challenge was ensuring everyone was on the same page with technical jargon and project goals. I facilitated regular meetings to align our objectives and encouraged open communication to address any misunderstandings promptly.\"  \n\n",
            "How do you approach explaining complex technical concepts to non-technical stakeholders?\n  \"I focus on using clear, simple language. charts and graphs can also make complex data more understandable. For example, when explaining machine learning models, I often use visualizations to show how data points are classified or predicted, making it easier for non-technical stakeholders to grasp the concepts.\"  ",
            "Describe a situation where you had to collaborate with a multidisciplinary team. What were the challenges and how did you address them?\n  \"In the EV charger location project, we had team members from diverse backgrounds, including project manager, engineers, and business analysts. One challenge was ensuring everyone was on the same page with technical jargon and project goals. I facilitated regular meetings to align our objectives and encouraged open communication to address any misunderstandings promptly.\"  ",
            "Creative and Innovative Thinking\nIn your fashion career, you mentioned creating a best-selling product. Can you share more about the creative process behind this success?\n  \"The creative process involved closely monitoring fashion trends, analyzing market demands, and collaborating with designers and suppliers. I used platforms like Pinterest and runway shows to gather inspiration and combined this with customer feedback to create a product that resonated with our target audience. Iterative testing and refinement were key to ensuring the product’s success.\"  \nHow do you approach innovation in your data science projects? Can you provide an example where you applied a creative solution to a technical problem?\n  \"I approach innovation by keeping an open mind and continuously exploring new methodologies and tools. In the EV charger location project, we creatively combined traditional clustering techniques with GIS data analysis to enhance our location predictions, which was a novel approach that significantly improved the accuracy of our results.\"  \n\n",
            "In your fashion career, you mentioned creating a best-selling product. Can you share more about the creative process behind this success?\n  \"The creative process involved closely monitoring fashion trends, analyzing market demands, and collaborating with designers and suppliers. I used platforms like Pinterest and runway shows to gather inspiration and combined this with customer feedback to create a product that resonated with our target audience. Iterative testing and refinement were key to ensuring the product’s success.\"  ",
            "How do you approach innovation in your data science projects? Can you provide an example where you applied a creative solution to a technical problem?\n  \"I approach innovation by keeping an open mind and continuously exploring new methodologies and tools. In the EV charger location project, we creatively combined traditional clustering techniques with GIS data analysis to enhance our location predictions, which was a novel approach that significantly improved the accuracy of our results.\"  ",
            "Alignment with MediaCity UK’s Goals\nHow do you envision your role as a Lab Technician contributing to the innovation projects at MediaCity?\n  \"I see myself contributing by bringing a unique perspective that blends creativity with technical expertise. My background in fashion and data science allows me to approach problems from different angles, fostering innovation. I am eager to support the team in integrating AI technologies into creative workflows, enhancing efficiency, and driving new possibilities in content creation.\"  \nWhat excites you the most about the opportunity to work at the Creative Industries Innovation Lab?\n  \"The most exciting aspect is the opportunity to work at the intersection of technology and creativity. MediaCity is known for its innovative projects, and being part of a team that pushes the boundaries of what AI can do in the creative industries is incredibly inspiring.\"  \nHow do you see AI transforming the creative industries, and what role do you want to play in this transformation?\n  \"AI has the potential to revolutionize content creation by automating tedious tasks, enhancing creative workflows, and enabling new forms of artistic expression. I want to play a role in developing and implementing AI-driven tools that empower artists and creators to explore new frontiers and streamline their processes.\"  \n\n",
            "How do you envision your role as a Lab Technician contributing to the innovation projects at MediaCity?\n  \"I see myself contributing by bringing a unique perspective that blends creativity with technical expertise. My background in fashion and data science allows me to approach problems from different angles, fostering innovation. I am eager to support the team in integrating AI technologies into creative workflows, enhancing efficiency, and driving new possibilities in content creation.\"  ",
            "What excites you the most about the opportunity to work at the Creative Industries Innovation Lab?\n  \"The most exciting aspect is the opportunity to work at the intersection of technology and creativity. MediaCity is known for its innovative projects, and being part of a team that pushes the boundaries of what AI can do in the creative industries is incredibly inspiring.\"  ",
            "How do you see AI transforming the creative industries, and what role do you want to play in this transformation?\n  \"AI has the potential to revolutionize content creation by automating tedious tasks, enhancing creative workflows, and enabling new forms of artistic expression. I want to play a role in developing and implementing AI-driven tools that empower artists and creators to explore new frontiers and streamline their processes.\"  ",
            "Future Aspirations\nWhere do you see yourself in five years, and how does this role at MediaCity fit into your career plans?\n  \"In five years, I see myself as a leading AI developer, working on groundbreaking projects that blend technology with creativity. This role at MediaCity is a perfect stepping stone, allowing me to apply my skills in a dynamic environment and contribute to innovative projects that will shape the future of the creative industries.\"  \nWhat are some areas of AI or machine learning that you are particularly interested in exploring further?\n  \"I am particularly interested in exploring generative models, such as Generative Adversarial Networks (GANs), and their applications in creating unique artistic content. Additionally, I am fascinated by the potential of AI in enhancing real-time workflows and interactive media, which are critical areas for the future of the creative industries.  \n\n",
            "Where do you see yourself in five years, and how does this role at MediaCity fit into your career plans?\n  \"In five years, I see myself as a leading AI developer, working on groundbreaking projects that blend technology with creativity. This role at MediaCity is a perfect stepping stone, allowing me to apply my skills in a dynamic environment and contribute to innovative projects that will shape the future of the creative industries.\"  ",
            "What are some areas of AI or machine learning that you are particularly interested in exploring further?\n  \"I am particularly interested in exploring generative models, such as Generative Adversarial Networks (GANs), and their applications in creating unique artistic content. Additionally, I am fascinated by the potential of AI in enhancing real-time workflows and interactive media, which are critical areas for the future of the creative industries.  ",
            "[[Catch 22 Data & Insight Analyst]] [[Interview preparation]]",
            "Can you describe your experience with data collection and validation in previous roles?\nI am currently involved in a new project focused on perinatal mums, run by the community garden where I have been volunteering for the past two years. This project aims to explore how connecting with nature can benefit their well-being. Although the project has just started, I am actively involved in the survey design process. My responsibilities include working with the volunteer coordinator to define the objectives and create survey questions that align with these goals. We are developing both quantitative (e.g., rating scales) and qualitative (e.g., open-ended) questions to capture comprehensive data. We plan to test the survey with a small group of perinatal mums to ensure clarity and effectiveness, making necessary adjustments based on their feedback. We will use both digital and paper formats to accommodate different preferences. Even though we are in the early stages, I am also preparing for the data analysis phase. After collecting the data, I will analyse it to draw insights, understand the impact of the sessions, and identify areas for improvement. These findings will be shared with stakeholders and the organization that provided funding for the project. This proactive and systematic approach ensures that our data collection process is robust and our findings will be reliable and actionable.\n\n",
            "I am currently involved in a new project focused on perinatal mums, run by the community garden where I have been volunteering for the past two years. This project aims to explore how connecting with nature can benefit their well-being. Although the project has just started, I am actively involved in the survey design process. My responsibilities include working with the volunteer coordinator to define the objectives and create survey questions that align with these goals. We are developing both quantitative (e.g., rating scales) and qualitative (e.g., open-ended) questions to capture comprehensive data. We plan to test the survey with a small group of perinatal mums to ensure clarity and effectiveness, making necessary adjustments based on their feedback. We will use both digital and paper formats to accommodate different preferences. Even though we are in the early stages, I am also preparing for the data analysis phase. After collecting the data, I will analyse it to draw insights, understand the impact of the sessions, and identify areas for improvement. These findings will be shared with stakeholders and the organization that provided funding for the project. This proactive and systematic approach ensures that our data collection process is robust and our findings will be reliable and actionable.",
            "How have you ensured data quality when working with frontline staff or other data collectors?\nWhile I haven't had direct experience in ensuring data quality with frontline staff or data collectors, I have developed strong skills in communication, collaboration, and process improvement that are relevant to this aspect of the role. In my previous positions, I have played a key role in training and supporting team members to stick to organizational standards and procedures. I have conducted training sessions on various topics, emphasizing the importance of accuracy and attention to detail in tasks. Although these sessions were not specifically focused on data entry, the principles of ensuring quality and consistency are applicable across different domains. Furthermore, I have experience in implementing process improvements to enhance efficiency and effectiveness. While this may not directly relate to data validation, the mindset of continuous improvement can be applied to developing strategies for maintaining data quality standards. In this role, I am eager to leverage my communication and process improvement skills to collaborate effectively with frontline staff and other data collectors. By fostering a culture of accountability and providing ongoing support and feedback, I believe we can collectively ensure that data quality standards are upheld.\n\n",
            "While I haven't had direct experience in ensuring data quality with frontline staff or data collectors, I have developed strong skills in communication, collaboration, and process improvement that are relevant to this aspect of the role. In my previous positions, I have played a key role in training and supporting team members to stick to organizational standards and procedures. I have conducted training sessions on various topics, emphasizing the importance of accuracy and attention to detail in tasks. Although these sessions were not specifically focused on data entry, the principles of ensuring quality and consistency are applicable across different domains. Furthermore, I have experience in implementing process improvements to enhance efficiency and effectiveness. While this may not directly relate to data validation, the mindset of continuous improvement can be applied to developing strategies for maintaining data quality standards. In this role, I am eager to leverage my communication and process improvement skills to collaborate effectively with frontline staff and other data collectors. By fostering a culture of accountability and providing ongoing support and feedback, I believe we can collectively ensure that data quality standards are upheld.",
            "What tools and methods do you use for combining qualitative and quantitative data?\nIn my experience, I primarily use Python for combining qualitative and quantitative data. For Quantitative Data, I use Pandas for data manipulation and analysis. It’s excellent for handling large datasets, performing statistical analysis, and preparing data for visualization.\nNumPy and SciPy: These libraries help with numerical computations and performing complex mathematical operations.\n\n\nFor categorical qualitative data, I use one-hot encoding to convert categories into binary vectors. This allows me to integrate qualitative data into numerical analyses seamlessly.\nLabel Encoding: When dealing with ordinal qualitative data, I assign numerical values to different categories to facilitate analysis.\nFor example, in a recent project, I will be collecting survey data that included both numerical ratings and categorical feedback. I used one-hot encoding to transform the categorical feedback into a numerical format, which allowed me to analyze and visualize the data together. This approach provided a comprehensive view of the data, making it easier to draw actionable insights.For reporting, I often use PowerBI to create visualizations that blend both data types, providing a comprehensive view of insights.\n\n\n\n",
            "In my experience, I primarily use Python for combining qualitative and quantitative data. For Quantitative Data, I use Pandas for data manipulation and analysis. It’s excellent for handling large datasets, performing statistical analysis, and preparing data for visualization.\nNumPy and SciPy: These libraries help with numerical computations and performing complex mathematical operations.\n\n",
            "NumPy and SciPy: These libraries help with numerical computations and performing complex mathematical operations.",
            "For categorical qualitative data, I use one-hot encoding to convert categories into binary vectors. This allows me to integrate qualitative data into numerical analyses seamlessly.\nLabel Encoding: When dealing with ordinal qualitative data, I assign numerical values to different categories to facilitate analysis.\nFor example, in a recent project, I will be collecting survey data that included both numerical ratings and categorical feedback. I used one-hot encoding to transform the categorical feedback into a numerical format, which allowed me to analyze and visualize the data together. This approach provided a comprehensive view of the data, making it easier to draw actionable insights.For reporting, I often use PowerBI to create visualizations that blend both data types, providing a comprehensive view of insights.\n\n",
            "Label Encoding: When dealing with ordinal qualitative data, I assign numerical values to different categories to facilitate analysis.",
            "For example, in a recent project, I will be collecting survey data that included both numerical ratings and categorical feedback. I used one-hot encoding to transform the categorical feedback into a numerical format, which allowed me to analyze and visualize the data together. This approach provided a comprehensive view of the data, making it easier to draw actionable insights.For reporting, I often use PowerBI to create visualizations that blend both data types, providing a comprehensive view of insights.",
            "Can you give an example of a complex data analysis project you have led? What were the outcomes?\nAt ABC Inc., I led a project to analyze customer churn. Using a combination of logistic regression and decision tree models, I identified key factors contributing to churn. The insights led to targeted retention strategies, reducing churn by 15% over six months.\n\n",
            "At ABC Inc., I led a project to analyze customer churn. Using a combination of logistic regression and decision tree models, I identified key factors contributing to churn. The insights led to targeted retention strategies, reducing churn by 15% over six months.",
            "How do you stay current with advancements in data analytics, AI, ML, and data visualization?\nI regularly participate in online courses from platforms like Coursera and attend industry conferences. I am also an active member of several professional networks and online forums where I exchange knowledge with peers and stay updated on the latest trends and technologies.\n\n",
            "I regularly participate in online courses from platforms like Coursera and attend industry conferences. I am also an active member of several professional networks and online forums where I exchange knowledge with peers and stay updated on the latest trends and technologies.",
            "Describe your experience with using CMS systems like Links CarePath or similar.\nIn my previous role, I used Salesforce as our CMS. I customized the system to fit our specific data collection needs, integrated it with external data sources, and ensured data was consistently recorded and validated. My familiarity with similar systems would allow me to quickly adapt to Links CarePath.\n\n",
            "In my previous role, I used Salesforce as our CMS. I customized the system to fit our specific data collection needs, integrated it with external data sources, and ensured data was consistently recorded and validated. My familiarity with similar systems would allow me to quickly adapt to Links CarePath.",
            "How have you utilized tools like PowerBI for reporting and creating dashboards?\nI have extensive experience using PowerBI to create interactive dashboards that provide real-time insights into key performance indicators. I design dashboards with drill-down capabilities to allow users to explore data at different levels of detail, enhancing decision-making processes.\n\n",
            "I have extensive experience using PowerBI to create interactive dashboards that provide real-time insights into key performance indicators. I design dashboards with drill-down capabilities to allow users to explore data at different levels of detail, enhancing decision-making processes.",
            "What strategies have you employed to support and train team members to improve data collection and analysis processes?\nI developed a comprehensive training program that included hands-on workshops, documentation, and regular Q&A sessions. I also established a mentorship system where more experienced team members supported new hires, fostering a culture of continuous learning and improvement.\n\n",
            "I developed a comprehensive training program that included hands-on workshops, documentation, and regular Q&A sessions. I also established a mentorship system where more experienced team members supported new hires, fostering a culture of continuous learning and improvement.",
            "Can you discuss a time when your data analysis significantly influenced organizational decision-making?\nAt my last job, my analysis of sales data revealed a decline in a particular product segment. I presented these findings to the management team, along with recommendations for targeted marketing campaigns. This led to a 20% increase in sales for that segment over the next quarter.\n\n",
            "At my last job, my analysis of sales data revealed a decline in a particular product segment. I presented these findings to the management team, along with recommendations for targeted marketing campaigns. This led to a 20% increase in sales for that segment over the next quarter.",
            "How do you handle and prioritize ad hoc data requests from senior stakeholders or external partners?\nI prioritize requests based on urgency and impact. I maintain a request log to track and manage these requests efficiently. Communication is key; I ensure stakeholders are informed about expected timelines and any potential delays.\n\n",
            "I prioritize requests based on urgency and impact. I maintain a request log to track and manage these requests efficiently. Communication is key; I ensure stakeholders are informed about expected timelines and any potential delays.",
            "Describe your experience in predictive data modeling and forecasting.\nI have built predictive models using Python and R to forecast customer behavior and demand trends. For instance, I developed a predictive model for inventory management that reduced stockouts by 30% and minimized overstock by 20%.\n\n",
            "I have built predictive models using Python and R to forecast customer behavior and demand trends. For instance, I developed a predictive model for inventory management that reduced stockouts by 30% and minimized overstock by 20%.",
            "How have you contributed to policy development or strategic planning through data insights?\nMy data insights have often informed strategic decisions, such as identifying new market opportunities or optimizing resource allocation. For example, my analysis on workforce efficiency led to the adoption of new scheduling policies, improving overall productivity by 10%.\n\n",
            "My data insights have often informed strategic decisions, such as identifying new market opportunities or optimizing resource allocation. For example, my analysis on workforce efficiency led to the adoption of new scheduling policies, improving overall productivity by 10%.",
            "What approaches do you take to ensure your reports and insights are easily understandable to non-technical stakeholders?\nI focus on clear and concise communication, using visuals like charts and graphs to convey complex data insights. I also provide executive summaries highlighting key findings and actionable recommendations, avoiding technical jargon.\n\n",
            "I focus on clear and concise communication, using visuals like charts and graphs to convey complex data insights. I also provide executive summaries highlighting key findings and actionable recommendations, avoiding technical jargon.",
            "Can you provide an example of how you have used data to improve service performance?\nBy analyzing customer feedback and operational data, I identified bottlenecks in our service delivery process. Implementing changes based on these insights, such as optimizing staffing levels and revising service protocols, led to a 15% improvement in service efficiency.\n\n",
            "By analyzing customer feedback and operational data, I identified bottlenecks in our service delivery process. Implementing changes based on these insights, such as optimizing staffing levels and revising service protocols, led to a 15% improvement in service efficiency.",
            "Describe a situation where you identified a data quality issue and how you resolved it.\nDuring a data migration project, I discovered discrepancies between old and new data sets. I implemented a thorough data validation process, corrected the errors, and established ongoing data quality monitoring to prevent future issues.\n\n",
            "During a data migration project, I discovered discrepancies between old and new data sets. I implemented a thorough data validation process, corrected the errors, and established ongoing data quality monitoring to prevent future issues.",
            "How do you manage and delegate tasks to support staff, such as an Administrative Officer, in a data-driven environment?\nI delegate tasks based on individual strengths and provide clear instructions and deadlines. Regular check-ins ensure progress and address any challenges. I also encourage a collaborative approach, where support staff can contribute ideas and solutions.\n\n",
            "I delegate tasks based on individual strengths and provide clear instructions and deadlines. Regular check-ins ensure progress and address any challenges. I also encourage a collaborative approach, where support staff can contribute ideas and solutions.",
            "What is your experience with developing and managing surveys and forms for data collection?\nI have designed and managed numerous surveys using tools like SurveyMonkey and Google Forms. My approach includes pre-testing surveys to ensure clarity and relevance, followed by thorough analysis of the collected data to derive actionable insights.\n\n",
            "I have designed and managed numerous surveys using tools like SurveyMonkey and Google Forms. My approach includes pre-testing surveys to ensure clarity and relevance, followed by thorough analysis of the collected data to derive actionable insights.",
            "How do you ensure data integrity when integrating data from multiple sources?\nI use ETL (Extract, Transform, Load) processes to ensure data consistency and integrity. This involves cleaning data, resolving discrepancies, and validating data accuracy before integration. Regular audits and automated data quality checks help maintain ongoing integrity.\n\n",
            "I use ETL (Extract, Transform, Load) processes to ensure data consistency and integrity. This involves cleaning data, resolving discrepancies, and validating data accuracy before integration. Regular audits and automated data quality checks help maintain ongoing integrity.",
            "Can you describe your experience with developing real-time tracking systems for performance and operational oversight?\nI developed a real-time tracking system using PowerBI that integrated with our operational databases. This system provided live updates on key metrics, enabling managers to make informed decisions quickly and respond to issues proactively.\n\n",
            "I developed a real-time tracking system using PowerBI that integrated with our operational databases. This system provided live updates on key metrics, enabling managers to make informed decisions quickly and respond to issues proactively.",
            "How do you balance the need for timely reporting with ensuring data accuracy and thorough analysis?\nI prioritize establishing robust data collection and validation processes upfront, which streamlines subsequent analysis and reporting. By automating routine tasks and leveraging efficient analytical tools, I ensure timely and accurate reporting without compromising on quality.\n\n",
            "I prioritize establishing robust data collection and validation processes upfront, which streamlines subsequent analysis and reporting. By automating routine tasks and leveraging efficient analytical tools, I ensure timely and accurate reporting without compromising on quality.",
            "[[Project]] summarization\n[[Regression project]] predicting home price in Bangalore\nKaggle dataset, import the packages\n\n\n[[Classification project]] Analysed HR Data and performed EDA and use random forest classification predicting whether an employee will leave the company a binary classification task: predicting whether an employee will leave the company (left column) based on various features related to job satisfaction, performance, work conditions\n\nmethodology: data exploration and data cleaning, standardize column names,\n\n\n",
            "[[Regression project]] predicting home price in Bangalore\nKaggle dataset, import the packages\n\n",
            "Kaggle dataset, import the packages",
            "[[Classification project]] Analysed HR Data and performed EDA and use random forest classification predicting whether an employee will leave the company a binary classification task: predicting whether an employee will leave the company (left column) based on various features related to job satisfaction, performance, work conditions",
            "\nmethodology: data exploration and data cleaning, standardize column names,\n"
        ]
    },
    {
        "id": "2024_05_18.md",
        "name": "2024_05_18",
        "content": [
            "-\n- [[Machine Learning course]] https://www.youtube.com/watch?v=i_LwzRVP7bg\n    - focus on algorithms help computer\n    - [[AI]] vs [[ML]] vs [[DS]] #[[Artificial Intelligence]] #[[Machine Learning]] #[[Data Science]]\n        - AI is an area of computer science, to enable computers and machines to perform human-like tasks and simulate human behaviour\n        - ML is subset of AI tries to solve a specific problem and make predictions using data.\n        - DS is a field attempts to find patterns and draw insights from data (using Machine Learning)\n- [[Features]] #[[Machine Learning]] Input to model\n    - [[Qualitative]] - categorical data(finite number of categories or groups),\n        - [[nominal data]] no inherent order, e.g. Gender, multiple nationality, using [[ONE-HOT ENCODING]] 0,1 - '1' if matches category\n        - [[ordinal data]] inherent order, e.g. different age groups(babies, toddlers, teenager, young adults, adults, senior adults OR different ratings like bad, not so good, mediocre, good and great ), mark them in numbers 1,2,3,4,5...\n    - [[Quantitative]] - numerical valued data(could be discrete or continuous) , e.g. easter egg hunt\n- [[Output]] #[[prediction]]\n    - Types of prediction\n        - Classification - predict discrete classes, \n          logseq.order-list-type:: number\n            - multiclass classification - hotdog, pizza, ice-cream\n            - Binary classification - hotdog or not hotdog, OR positive/negative, OR Spam/not spam\n        - Regression - predict continuous values, e.g. predict house price\n          logseq.order-list-type:: number\n- [[MODEL]]\n    - Training dataset 60%, validation dataset 20%, Testing dataset 20% or 80%, 10% ,10%\n    - Model does well, in reality to use the model to predict (e.g. if someone has diabetes ) , but need to assess how well the model can generalize on new dataset - splitting the whole dataset to train, validation, testing based on the size of the dataset. Compare the difference between prediction and true values on training dataset, which is known as loss, in some numerical quantitative. And then make adjustments to the model(training).\n    - After adjustment/training, put validation set through the model, as a reality check, to ensure the model can handle unseen data. To check what the [[loss]] is there. The smaller number of loss the better( loss =0.5 better than loss = 1.3).\n    -\n    -\n-"
        ]
    },
    {
        "id": "2024_05_19.md",
        "name": "2024_05_19",
        "content": [
            "meeting agenda [[Knelyfe labs]]\nbasic function video introduction.\n  logseq.order-list-type:: number\nNicola created website consultation email info@knelyfelabs.com, pw: V&XWVXBEM4<>7rC=\n  logseq.order-list-type:: number\nskills can be taught: SQL, POWER BI, PYTHON\n  logseq.order-list-type:: number\nvideo calendar( we can introduce who we are)\n  logseq.order-list-type:: number\nfuture revision: github introduction\ntiingo(API)\nJing to learn how to pull data use API and use Power BI create visualisation - 4 videos (2 by Nicola and 2 by Jing, 1st video to be out in 3 weeks, we figure out the script together)\nTODO learn getting data from an api https://github.dev/nsagay/Stocks-Analysis/blob/main/Stocks%20Analysis.ipynb\n\nNext meeting to be confirmed through poll(in the week of 3rd of June)\n\n\n",
            "basic function video introduction.\n  logseq.order-list-type:: number",
            "Nicola created website consultation email info@knelyfelabs.com, pw: V&XWVXBEM4<>7rC=\n  logseq.order-list-type:: number",
            "skills can be taught: SQL, POWER BI, PYTHON\n  logseq.order-list-type:: number",
            "video calendar( we can introduce who we are)\n  logseq.order-list-type:: number",
            "future revision: github introduction",
            "tiingo(API)",
            "Jing to learn how to pull data use API and use Power BI create visualisation - 4 videos (2 by Nicola and 2 by Jing, 1st video to be out in 3 weeks, we figure out the script together)",
            "TODO learn getting data from an api https://github.dev/nsagay/Stocks-Analysis/blob/main/Stocks%20Analysis.ipynb",
            "\nNext meeting to be confirmed through poll(in the week of 3rd of June)\n"
        ]
    },
    {
        "id": "2024_06_03.md",
        "name": "2024_06_03",
        "content": [
            "[[Knelyfe Labs]] meeting agenda :\nAPI pull data(Jing)\nhttps://github.com/ranaroussi/yfinance\nhttps://www.alphavantage.co/\n\n\nBiggest issue: dataset  (FastFuture Kishan support? Nicola reached out)\n\n",
            "API pull data(Jing)\nhttps://github.com/ranaroussi/yfinance\nhttps://www.alphavantage.co/\n\n",
            "https://github.com/ranaroussi/yfinance",
            "https://www.alphavantage.co/",
            "Biggest issue: dataset  (FastFuture Kishan support? Nicola reached out)",
            "Focus area: Sustainability",
            "Video(Amoke) - research on similar videos, channels, format (data analyst, powebi) story board",
            "Nicola: Python, API (enjoy ParkLife this week)",
            "Sowjanya: tiktok"
        ]
    },
    {
        "id": "2024_06_04.md",
        "name": "2024_06_04",
        "content": [
            "[[MITIH]] 10:00-15:30\nInnovate UK\n3.2 million investments\ncreative  R&D\nhalf for projects up to £100,000, half for employees\n14 projects spatial education, prepreduction,\nCo-investment\nImmersive analytics\nPersonalised content\nVive\nCurious Magic\nPathway\nEpic games - map-meta(audio2 meta),vcam\nUnreal project(maya project)\nOpenAI webui\n\n",
            "Innovate UK",
            "3.2 million investments",
            "creative  R&D",
            "half for projects up to £100,000, half for employees",
            "14 projects spatial education, prepreduction,",
            "Co-investment",
            "Immersive analytics",
            "Personalised content",
            "Vive",
            "Curious Magic",
            "Pathway",
            "Epic games - map-meta(audio2 meta),vcam",
            "Unreal project(maya project)",
            "OpenAI webui"
        ]
    },
    {
        "id": "2024_06_06.md",
        "name": "2024_06_06",
        "content": [
            "[[Blender]] #Blender #[[Navigation tools]]\nhttps://vagon.io/blog/blender-shortcuts-hotkeys/\nFile Menu:\nNew File: Ctrl + N\nOpen File: Ctrl + O\nSave File: Ctrl + S\nSave File As…: Shift + Ctrl + S\nQuit Blender: Ctrl + Q\n\n\nEdit Menu:\nUndo: Ctrl + Z\nRedo: Ctrl + Y\nRepeat Last Action: Shift + R\nMenu Search: F3\nRename: F2\n\n\nRender Menu:\nRender Image: F12\nRender Animation: Ctrl + F12\nView Image: F11\nView Animation: Ctrl + F11\n\n\nWindow Menu:\nNext Workspace: Ctrl + Page Down\nPrevious Workspace: Ctrl + Page Up\n\n\n\n",
            "https://vagon.io/blog/blender-shortcuts-hotkeys/",
            "File Menu:\nNew File: Ctrl + N\nOpen File: Ctrl + O\nSave File: Ctrl + S\nSave File As…: Shift + Ctrl + S\nQuit Blender: Ctrl + Q\n\n",
            "New File: Ctrl + N",
            "Open File: Ctrl + O",
            "Save File: Ctrl + S",
            "Save File As…: Shift + Ctrl + S",
            "Quit Blender: Ctrl + Q",
            "Edit Menu:\nUndo: Ctrl + Z\nRedo: Ctrl + Y\nRepeat Last Action: Shift + R\nMenu Search: F3\nRename: F2\n\n",
            "Undo: Ctrl + Z",
            "Redo: Ctrl + Y",
            "Repeat Last Action: Shift + R",
            "Menu Search: F3",
            "Rename: F2",
            "Render Menu:\nRender Image: F12\nRender Animation: Ctrl + F12\nView Image: F11\nView Animation: Ctrl + F11\n\n",
            "Render Image: F12",
            "Render Animation: Ctrl + F12",
            "View Image: F11",
            "View Animation: Ctrl + F11",
            "Window Menu:\nNext Workspace: Ctrl + Page Down\nPrevious Workspace: Ctrl + Page Up\n\n",
            "Next Workspace: Ctrl + Page Down",
            "Previous Workspace: Ctrl + Page Up"
        ]
    },
    {
        "id": "2024_06_07.md",
        "name": "2024_06_07",
        "content": [
            "Animated 3D line graph and 3D bar chart",
            "[[plotly]]\nhttps://www.youtube.com/watch?v=TlXSlV4Ng40\n\n",
            "https://www.youtube.com/watch?v=TlXSlV4Ng40",
            "[[Immersive analytics]] is transforming data visualization by using [[virtual reality]] (VR) and [[augmented reality]] (AR) to create interactive environments where you can explore data in three dimensions. This trend allows you to engage with data spatially, making complex datasets more intuitive and revealing insights that might be missed in two-dimensional representations. Imagine being able to \"walk\" through your data or manipulate it with hand gestures; that's the promise of immersive analytics.",
            "[[3D rendering]]",
            "[[3D modelling]]",
            "\n[[3D animation]]\n"
        ]
    },
    {
        "id": "2024_06_14.md",
        "name": "2024_06_14",
        "content": [
            "[[Github]] [[Git]] [[Github desktop]]\nhttps://www.youtube.com/watch?v=8Dd7KRpKeaE\n\n",
            "https://www.youtube.com/watch?v=8Dd7KRpKeaE",
            "Data [[Spring]]",
            "[[Knowledge Graph]]#[[data spring system knowledge graph]]\nHow [[Knowledge Graphs]] Make [[Data]] More Useful to Organizations #[[Data Science]]\n[[Knowledge Graphs]] also represent a major segment of the data graphs and [[visualizations]] landscape in general, a market that’s growing exponentially. By 2025, according to Gartner data, graph technologies will be used in 80% of [[data and analytics innovations]] , up from 10% in 2021, “facilitating rapid decision-making across the enterprise,” the analyst forecasted.\nhttps://thenewstack.io/how-knowledge-graphs-make-data-more-useful-to-organizations/\n\n\n\n",
            "How [[Knowledge Graphs]] Make [[Data]] More Useful to Organizations #[[Data Science]]\n[[Knowledge Graphs]] also represent a major segment of the data graphs and [[visualizations]] landscape in general, a market that’s growing exponentially. By 2025, according to Gartner data, graph technologies will be used in 80% of [[data and analytics innovations]] , up from 10% in 2021, “facilitating rapid decision-making across the enterprise,” the analyst forecasted.\nhttps://thenewstack.io/how-knowledge-graphs-make-data-more-useful-to-organizations/\n\n",
            "[[Knowledge Graphs]] also represent a major segment of the data graphs and [[visualizations]] landscape in general, a market that’s growing exponentially. By 2025, according to Gartner data, graph technologies will be used in 80% of [[data and analytics innovations]] , up from 10% in 2021, “facilitating rapid decision-making across the enterprise,” the analyst forecasted.",
            "https://thenewstack.io/how-knowledge-graphs-make-data-more-useful-to-organizations/",
            "[[WIKIDATA]][[SPARQL]]\nhttps://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial\n\n",
            "https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial"
        ]
    },
    {
        "id": "2024_06_17.md",
        "name": "2024_06_17",
        "content": [
            "[[3d nodes project]] [[Omniverse]]",
            "[[11Elevenlabs]] [[AI Voice]] [[Dreamlab podcast]]",
            "[[Showrunner]] #Rob",
            "[[Unreal engine avalanche]]",
            "[[EQ-bench]] #[[evaluation Logseq]]",
            "[[Ontology]]",
            "[[Knowledge Graph]]",
            "[[Mermaid diagram]] #[[mermaid live]]",
            "[[Three.js]]",
            "[[Spring class]]",
            "[[Brendan Dawes]] #[[data visualisation]]\nhttps://brendandawes.com/filter:data\n\n",
            "https://brendandawes.com/filter:data",
            "\n[[Universal Scene Description]] [[USD]]\n"
        ]
    },
    {
        "id": "2024_06_19.md",
        "name": "2024_06_19",
        "content": [
            "[[API]]",
            "[[AGI]]",
            "[[gene editing]] correcting [[genetic defects]] , changing eye color, personalizsed medication",
            "[[Quantum computing]]qubits [[cryptographic]] [[molecure]][[analyze vast datasets]]",
            "[[Neuralink]]high-brand width implanted to brain, brain computer, neurologistical, improving memory, sharing thoughts. accelrate learning process. like computer download software.",
            "[[Humanoid robots]] mimic human body and behavior, sensors, Sophia,Ameca.",
            "[[Generative AI]]",
            "[[]]",
            "\nAI Project Hacking\n- https://www.linkedin.com/pulse/ai-project-hacking-dreamlabinstitute-6u5ue/?trackingId=Q0coE4auTDidpTDumUnVXg%3D%3D\n",
            "[[LLM smashing]]"
        ]
    },
    {
        "id": "2024_06_20.md",
        "name": "2024_06_20",
        "content": [
            "[[MITIH]] focuses its support on projects within\n  key sectors, including  ",
            "\n\nInnovation in Gaming and Interactive Technologies\n\n",
            "Innovation in Gaming and Interactive Technologies",
            "Shaping various sectors, including Esports.",
            "\n\nVirtual and Augmented Reality Experiences\n\n",
            "Virtual and Augmented Reality Experiences",
            "Future-proofing businesses and cultivating new audiences.",
            "\n\nVirtual Production Techniques and Processes\n\n",
            "Virtual Production Techniques and Processes",
            "\nExpanding the creative potential of Film, VFX,and TV.\n",
            "[[Neural networks]] and [[Knowledge Graphs]] are two distinct approaches in artificial intelligence and data representation, each with its own strengths and applications:",
            "\nNeural Networks:\n\nStructure: Inspired by biological neural networks, they consist of interconnected nodes (neurons) organized in layers.\nLearning: They learn patterns from data through training, adjusting connection weights to improve performance.\nFunction: Excel at pattern recognition, classification, prediction, and handling unstructured data.\nData processing: Work well with large amounts of numerical or categorical data.\nExplainability: Often considered \"black boxes\" due to difficulty in interpreting their decision-making process.\n\n",
            "Neural Networks:",
            "Structure: Inspired by biological neural networks, they consist of interconnected nodes (neurons) organized in layers.",
            "Learning: They learn patterns from data through training, adjusting connection weights to improve performance.",
            "Function: Excel at pattern recognition, classification, prediction, and handling unstructured data.",
            "Data processing: Work well with large amounts of numerical or categorical data.",
            "Explainability: Often considered \"black boxes\" due to difficulty in interpreting their decision-making process.",
            "\nKnowledge Graphs:\n\nStructure: Represent information as a network of entities (nodes) and their relationships (edges).\nOrganization: Based on semantic relationships and ontologies, often using triples (subject-predicate-object).\nFunction: Excellent for representing complex, interconnected information and supporting reasoning tasks.\nData processing: Well-suited for handling structured, semantic data and supporting query answering.\nExplainability: Typically more transparent and interpretable than neural networks.\n\n",
            "Knowledge Graphs:",
            "Structure: Represent information as a network of entities (nodes) and their relationships (edges).",
            "Organization: Based on semantic relationships and ontologies, often using triples (subject-predicate-object).",
            "Function: Excellent for representing complex, interconnected information and supporting reasoning tasks.",
            "Data processing: Well-suited for handling structured, semantic data and supporting query answering.",
            "Explainability: Typically more transparent and interpretable than neural networks.",
            "\nKey differences:\n\nLearning vs. Representation: Neural networks learn from data, while knowledge graphs represent existing knowledge.\nData types: Neural networks excel with unstructured data, knowledge graphs with structured, semantic data.\nReasoning: Knowledge graphs support logical inference, while neural networks are better at pattern-based predictions.\nTransparency: Knowledge graphs offer better explainability compared to neural networks.\n\n",
            "Key differences:",
            "Learning vs. Representation: Neural networks learn from data, while knowledge graphs represent existing knowledge.",
            "Data types: Neural networks excel with unstructured data, knowledge graphs with structured, semantic data.",
            "Reasoning: Knowledge graphs support logical inference, while neural networks are better at pattern-based predictions.",
            "Transparency: Knowledge graphs offer better explainability compared to neural networks.",
            "\nWould you like me to elaborate on any specific aspect of these differences?\n",
            "Would you like me to elaborate on any specific aspect of these differences?"
        ]
    },
    {
        "id": "2024_06_21.md",
        "name": "2024_06_21",
        "content": [
            "[[Gephi]] Network graphs for Nodes and Edges",
            "\n[[API]]\n-"
        ]
    },
    {
        "id": "2024_06_22.md",
        "name": "2024_06_22",
        "content": [
            "[[USD]] is [[API]]",
            "[[Neo4j]]",
            "[[Space Tourism]]",
            "[[Lunar Tourism]]",
            "[[Internet of Things]]",
            "[[Mixed reality]] more immersive experience than AR, Meta,",
            "[[3D printing]] organs",
            "[[Solid-state batteries]] renewable energy",
            "[[Fusion power]] net energy gain",
            "[[Blockchain]]",
            "[[lab-grown meat]] customize taste texture",
            "[[Transformers]]\nPositional encoding\nattention\n\nself-attention\n-\n\n\n",
            "Positional encoding",
            "attention",
            "\nself-attention\n-\n"
        ]
    },
    {
        "id": "2024_06_24.md",
        "name": "2024_06_24",
        "content": [
            "splitting the node and get to [[Blender]]",
            "[[markdown files]] load to blender, ignore what logseq graph is like, getting familiar,",
            "[[Spring]]Mesh network,"
        ]
    },
    {
        "id": "collaboration.md",
        "name": "collaboration",
        "content": [
            "-"
        ]
    },
    {
        "id": "contents.md",
        "name": "contents",
        "content": [
            "-"
        ]
    }
]