{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b7a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown in c:\\users\\lolic\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lolic\\anaconda3\\lib\\site-packages (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install markdown pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9f90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import markdown\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id, name, content):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.content = content\n",
    "        self.edges = []\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, source, target, link_type):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.link_type = link_type\n",
    "\n",
    "def parse_markdown_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract front matter (YAML)\n",
    "    front_matter = re.search(r'^---(.*?)---', content, re.DOTALL)\n",
    "    if front_matter:\n",
    "        front_matter_content = front_matter.group(1)\n",
    "        metadata = yaml.safe_load(front_matter_content)\n",
    "        content = content.replace(front_matter.group(0), '')\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    # Extract links in the markdown content\n",
    "    links = re.findall(r'\\[\\[([^\\]]+)\\]\\]', content)\n",
    "\n",
    "    return metadata, links, content\n",
    "\n",
    "def create_graph_from_logseq(directory):\n",
    "    nodes = {}\n",
    "    edges = []\n",
    "\n",
    "    # Parse each markdown file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.md'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            metadata, links, content = parse_markdown_file(file_path)\n",
    "\n",
    "            node_id = metadata.get('id', filename)\n",
    "            node_name = metadata.get('title', filename.replace('.md', ''))\n",
    "            node = Node(node_id, node_name, content)\n",
    "            nodes[node_id] = node\n",
    "\n",
    "            for link in links:\n",
    "                target_node_name = link\n",
    "                edge = Edge(node_id, target_node_name, 'link')\n",
    "                node.edges.append(edge)\n",
    "                edges.append(edge)\n",
    "\n",
    "    return nodes, edges\n",
    "\n",
    "# Example usage\n",
    "logseq_directory = r'C:\\Users\\lolic\\githubs\\JingSpringThing\\spatialKnowledgeGraph\\pythonCode\\demoData'\n",
    "nodes, edges = create_graph_from_logseq(logseq_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0364a3c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbpy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `nodes` and `edges` are from the previous script\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Example dummy nodes and edges for illustration\u001b[39;00m\n\u001b[0;32m      5\u001b[0m nodes \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m: Node(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNode1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent1\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m: Node(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNode2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent2\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m }\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bpy'"
     ]
    }
   ],
   "source": [
    "import bpy\n",
    "\n",
    "# Assuming `nodes` and `edges` are from the previous script\n",
    "# Example dummy nodes and edges for illustration\n",
    "nodes = {\n",
    "    '1': Node('1', 'Node1', 'Content1'),\n",
    "    '2': Node('2', 'Node2', 'Content2'),\n",
    "}\n",
    "edges = [Edge('1', '2', 'link')]\n",
    "\n",
    "def create_blender_objects(nodes, edges):\n",
    "    for node_id, node in nodes.items():\n",
    "        bpy.ops.mesh.primitive_uv_sphere_add(radius=1, location=(node_id * 2, 0, 0))\n",
    "        obj = bpy.context.object\n",
    "        obj.name = node.name\n",
    "        node.blender_object = obj\n",
    "\n",
    "    for edge in edges:\n",
    "        source_node = nodes[edge.source]\n",
    "        target_node = nodes[edge.target]\n",
    "        \n",
    "        if hasattr(source_node, 'blender_object') and hasattr(target_node, 'blender_object'):\n",
    "            start = source_node.blender_object.location\n",
    "            end = target_node.blender_object.location\n",
    "\n",
    "            bpy.ops.mesh.primitive_cylinder_add(\n",
    "                radius=0.1,\n",
    "                depth=(end - start).length,\n",
    "                location=(start + end) / 2\n",
    "            )\n",
    "            obj = bpy.context.object\n",
    "            obj.name = f\"{source_node.name}_to_{target_node.name}\"\n",
    "            obj.rotation_euler = (end - start).to_track_quat('Z', 'Y').to_euler()\n",
    "            \n",
    "# Run the function to create objects\n",
    "create_blender_objects(nodes, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413f1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id, name, content):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.content = content\n",
    "        self.edges = []\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, source, target, link_type):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.link_type = link_type\n",
    "\n",
    "def parse_markdown_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract front matter (YAML)\n",
    "    front_matter = re.search(r'^---(.*?)---', content, re.DOTALL)\n",
    "    if front_matter:\n",
    "        front_matter_content = front_matter.group(1)\n",
    "        metadata = yaml.safe_load(front_matter_content)\n",
    "        content = content.replace(front_matter.group(0), '')\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    # Extract links in the markdown content\n",
    "    links = re.findall(r'\\[\\[([^\\]]+)\\]\\]', content)\n",
    "\n",
    "    return metadata, links, content\n",
    "\n",
    "def create_graph_from_logseq(directory):\n",
    "    nodes = {}\n",
    "    edges = []\n",
    "\n",
    "    # Parse each markdown file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.md'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            metadata, links, content = parse_markdown_file(file_path)\n",
    "\n",
    "            node_id = metadata.get('id', filename)\n",
    "            node_name = metadata.get('title', filename.replace('.md', ''))\n",
    "            node = Node(node_id, node_name, content)\n",
    "            nodes[node_id] = node\n",
    "\n",
    "            for link in links:\n",
    "                target_node_name = link\n",
    "                edge = Edge(node_id, target_node_name, 'link')\n",
    "                node.edges.append(edge)\n",
    "                edges.append(edge)\n",
    "\n",
    "    return nodes, edges\n",
    "\n",
    "def node_to_dict(node):\n",
    "    return {\n",
    "        'id': node.id,\n",
    "        'name': node.name,\n",
    "        'content': node.content,\n",
    "        'edges': [{'source': edge.source, 'target': edge.target, 'link_type': edge.link_type} for edge in node.edges]\n",
    "    }\n",
    "\n",
    "def save_to_json(nodes, edges, nodes_file_path, edges_file_path):\n",
    "    nodes_list = [node_to_dict(node) for node in nodes.values()]\n",
    "    edges_list = [{'source': edge.source, 'target': edge.target, 'link_type': edge.link_type} for edge in edges]\n",
    "\n",
    "    with open(nodes_file_path, 'w', encoding='utf-8') as nodes_file:\n",
    "        json.dump(nodes_list, nodes_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    with open(edges_file_path, 'w', encoding='utf-8') as edges_file:\n",
    "        json.dump(edges_list, edges_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "logseq_directory = r'C:\\Users\\lolic\\githubs\\JingSpringThing\\spatialKnowledgeGraph\\pythonCode\\demoData'\n",
    "nodes, edges = create_graph_from_logseq(logseq_directory)\n",
    "\n",
    "# Save nodes and edges to JSON files\n",
    "nodes_file_path = 'nodes.json'\n",
    "edges_file_path = 'edges.json'\n",
    "save_to_json(nodes, edges, nodes_file_path, edges_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c1035bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: {}\n",
      "Edges: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id, name, content):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.content = content\n",
    "        self.edges = []\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, source, target, link_type):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.link_type = link_type\n",
    "\n",
    "def parse_markdown_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract front matter (YAML)\n",
    "    front_matter = re.search(r'^---(.*?)---', content, re.DOTALL)\n",
    "    if front_matter:\n",
    "        front_matter_content = front_matter.group(1)\n",
    "        metadata = yaml.safe_load(front_matter_content)\n",
    "        content = content.replace(front_matter.group(0), '')\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    # Extract links in the markdown content\n",
    "    links = re.findall(r'\\[\\[([^\\]]+)\\]\\]', content)\n",
    "\n",
    "    return metadata, links, content\n",
    "\n",
    "def create_graph_from_logseq(directory):\n",
    "    nodes = {}\n",
    "    edges = []\n",
    "\n",
    "    # Function to parse files in a given folder\n",
    "    def parse_folder(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith('.md'):\n",
    "                file_path = os.path.join(folder, filename)\n",
    "                print(f\"Parsing file: {file_path}\")\n",
    "                metadata, links, content = parse_markdown_file(file_path)\n",
    "                print(f\"Metadata: {metadata}\")\n",
    "                print(f\"Links: {links}\")\n",
    "\n",
    "                node_id = metadata.get('id', filename)\n",
    "                node_name = metadata.get('title', filename.replace('.md', ''))\n",
    "                node = Node(node_id, node_name, content)\n",
    "                nodes[node_id] = node\n",
    "\n",
    "                for link in links:\n",
    "                    target_node_name = link\n",
    "                    edge = Edge(node_id, target_node_name, 'link')\n",
    "                    node.edges.append(edge)\n",
    "                    edges.append(edge)\n",
    "\n",
    "    # Parse markdown files in 'journals' and 'pages' folders\n",
    "    journals_folder = os.path.join(directory, 'journals')\n",
    "    pages_folder = os.path.join(directory, 'pages')\n",
    "\n",
    "    if os.path.exists(journals_folder):\n",
    "        parse_folder(journals_folder)\n",
    "\n",
    "    if os.path.exists(pages_folder):\n",
    "        parse_folder(pages_folder)\n",
    "\n",
    "    return nodes, edges\n",
    "\n",
    "def node_to_dict(node):\n",
    "    return {\n",
    "        'id': node.id,\n",
    "        'name': node.name,\n",
    "        'content': node.content,\n",
    "        'edges': [{'source': edge.source, 'target': edge.target, 'link_type': edge.link_type} for edge in node.edges]\n",
    "    }\n",
    "\n",
    "def save_to_json(nodes, edges, nodes_file_path, edges_file_path):\n",
    "    nodes_list = [node_to_dict(node) for node in nodes.values()]\n",
    "    edges_list = [{'source': edge.source, 'target': edge.target, 'link_type': edge.link_type} for edge in edges]\n",
    "\n",
    "    with open(nodes_file_path, 'w', encoding='utf-8') as nodes_file:\n",
    "        json.dump(nodes_list, nodes_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    with open(edges_file_path, 'w', encoding='utf-8') as edges_file:\n",
    "        json.dump(edges_list, edges_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "logseq_directory = r'C:\\Users\\lolic\\githubs\\JingSpringThing\\spatialKnowledgeGraph\\pythonCode\\demoData'\n",
    "nodes, edges = create_graph_from_logseq(logseq_directory)\n",
    "print(f\"Nodes: {nodes}\")\n",
    "print(f\"Edges: {edges}\")\n",
    "\n",
    "# Save nodes and edges to JSON files\n",
    "nodes_file_path = 'nodes.json'\n",
    "edges_file_path = 'edges.json'\n",
    "save_to_json(nodes, edges, nodes_file_path, edges_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
